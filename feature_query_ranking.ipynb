{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_query_ranking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzf581hqhCiM"
      },
      "source": [
        "**加载模型**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfPHzuMge_GI"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras import backend\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Conv2D, Dropout\n",
        "from keras.layers import *\n",
        "import h5py\n",
        "from tensorflow.python.keras.utils import conv_utils\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from keras.initializers import glorot_uniform\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B086k-jNff-T"
      },
      "source": [
        "!wget https://digix-algo-challenge.obs.cn-east-2.myhuaweicloud.com/2020/cv/6rKDTsB6sX8A1O2DA2IAq7TgHPdSPxJF/test_data_A.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grW8UtJYjvPm"
      },
      "source": [
        "!unzip test_data_A.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNPpVE_JwFT3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import time \n",
        "from torch.utils.data import DataLoader, Sampler, Dataset\n",
        "from torchvision import datasets,transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaJPgjE9xoRd"
      },
      "source": [
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5oZzPy4hRSp"
      },
      "source": [
        "**读取模型**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc4TUocmqeIb"
      },
      "source": [
        "# 首先构建不带分类器的预训练模型\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "# 添加全局平均池化层\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "# 添加一个全连接层\n",
        "x = Dense(4096, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "# 添加一个分类器，我们有3097个类\n",
        "predictions = Dense(3097, activation='softmax')(x)\n",
        "# 构建我们需要训练的完整模型\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR6KoW90qCci"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIFHf4wKcbOe"
      },
      "source": [
        "model.load_weights('/content/drive/Shared drives/my_new_pan/5_resnet50_finetuned4096bn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQilB2YEI5TZ"
      },
      "source": [
        "import os\n",
        "#path为gallery路径\n",
        "def get_imlist(path):\n",
        "    return [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.jpg')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mim6CdGiI430"
      },
      "source": [
        "gallery = get_imlist('test_data_A/gallery')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQoqwk2MJ_dR"
      },
      "source": [
        "def prep_feat(path):\n",
        "  img = image.load_img(path, target_size=(224, 224))\n",
        "  img = image.img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = preprocess_input(img)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTs8kovm5Wc9"
      },
      "source": [
        "def extractFeatures_fc(img_path, model):\n",
        "  img = prep_feat(img_path)\n",
        "  features = model.predict(img)\n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so_EvqumwNRo"
      },
      "source": [
        "**Pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk1SV_HRwaQi"
      },
      "source": [
        "model = torch.load('/content/drive/Shared drives/my_new_pan/10.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nygESkw4y9w0"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z0NSwxLxKWc"
      },
      "source": [
        "import os\n",
        "#path为gallery路径\n",
        "def get_imlist(path):\n",
        "    return [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.jpg')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksI8UBmaxJ7l"
      },
      "source": [
        "def prep_feat(path):\n",
        "  img = Image.open(path)\n",
        "  img = transforms.RandomResizedCrop(224)(img)\n",
        "  img = transforms.ToTensor()(img)\n",
        "  if img.shape[0] == 1:\n",
        "    img = img.numpy()\n",
        "    img = np.concatenate((img, img, img))\n",
        "    img = torch.from_numpy(img)               \n",
        "  img = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(img)\n",
        "  img = torch.unsqueeze(img, dim=0)\n",
        "  return img.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6Lb5bi5yFT7"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLo4KzPayK4W"
      },
      "source": [
        "gallery = get_imlist('test_data_A/gallery')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45p7TKWMyZOf"
      },
      "source": [
        "def extractFeatures_fc(img_path, model):\n",
        "  img = prep_feat(img_path)\n",
        "  features = model(img)\n",
        "  return features.cpu().detach().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOry73-CwIVG"
      },
      "source": [
        "**未训练**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsqnXzDnvbdE"
      },
      "source": [
        "model = ResNet50(weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vKlZeus3KTp"
      },
      "source": [
        "for layer in model.layers:\n",
        "  print(layer.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xwTakOIhKr-"
      },
      "source": [
        "model = Model(inputs=model.input, outputs=model.get_layer('conv5_block2_out').output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8ojjLYijLDR"
      },
      "source": [
        "import os\n",
        "#path为gallery路径\n",
        "def get_imlist(path):\n",
        "    return [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.jpg')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hKuS3-Hnaj4"
      },
      "source": [
        "def prep_feat(path):\n",
        "  img = image.load_img(path, target_size=(224, 224))\n",
        "  img = image.img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = preprocess_input(img)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUPO8cDul44X"
      },
      "source": [
        "gallery = get_imlist('test_data_A/gallery')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwWqA0ubK6P1"
      },
      "source": [
        "def extractFeatures_fc(img_path, model):\n",
        "  img = prep_feat(img_path)\n",
        "  features = model.predict(img)\n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qCC6m8vla4a"
      },
      "source": [
        "**https://github.com/fmaglia/keras_rmac_plus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeaV4ysWjVfh"
      },
      "source": [
        "def calculateMAC(features): #max-pooling and l2-norm\n",
        "  mac = []\n",
        "  rows = features.shape[1] * features.shape[2]\n",
        "  cols = features.shape[3]\n",
        "  features1 = np.reshape(features, (rows, cols))\n",
        "  features2 = np.amax(features1, axis = 0)\n",
        "  features2 /= np.linalg.norm(features2, 2)\n",
        "  mac.append(features2)\n",
        "  return mac"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfcAdYXjyvZh"
      },
      "source": [
        "def calculateRMAC(features, L):\n",
        "  RMAC = []\n",
        "  W = features.shape[1]\n",
        "  H = features.shape[2]\n",
        "  for l in range(1,L+1):\n",
        "    if (l==1):\n",
        "      heightRegion = widthRegion = min(W,H)\n",
        "      if (W<H):\n",
        "        xRegions = 1\n",
        "        yRegions = 2\n",
        "      else:\n",
        "        xRegions = 2\n",
        "        yRegions = 1\n",
        "    else:\n",
        "      widthRegion = heightRegion = math.ceil(2*min(W,H)/(l+1))\n",
        "      if (l==2):\n",
        "        xRegions = 2\n",
        "        yRegions = 3\n",
        "      elif (l==3):\n",
        "        xRegions = 3\n",
        "        yRegions = 2\n",
        "\n",
        "    if (widthRegion * xRegions < W):\n",
        "        #not covered the image along width\n",
        "      widthRegion = math.ceil(W/xRegions)\n",
        "\n",
        "    if (heightRegion*yRegions < H):\n",
        "\t    heightRegion = math.ceil(H/yRegions)\n",
        "    \n",
        "    coefW = W / xRegions\n",
        "    coefH = H / yRegions \n",
        "\n",
        "\t\t# print(\"L:\",l,\" w:\",widthRegion,\" h:\",heightRegion,\"xRegions\",xRegions,\"yRegions\",yRegions)\n",
        "    for x in range(0,xRegions):\n",
        "      for y in range(0,yRegions):\n",
        "        initialX = round(x*coefW)\n",
        "        initialY = round(y*coefH)\n",
        "        finalX = initialX + widthRegion\n",
        "        finalY = initialY + heightRegion\n",
        "        if (finalX > W):\n",
        "          finalX = W\n",
        "          initialX = finalX - widthRegion\n",
        "        if (finalY > H):\n",
        "          finalY = H\n",
        "          initialY =  finalY - heightRegion\n",
        "\n",
        "\t\t\t\t# print(\" X \",initialX,\":\", finalX,\" Y \", initialY,\":\", finalY)\n",
        "\n",
        "        featureRegion = features[:,initialX:finalX,initialY:finalY,:] #(old implementation)\n",
        "        RMAC.append(calculateMAC(featureRegion))\n",
        "  return RMAC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Has22G1wjWZV"
      },
      "source": [
        "def extractFeatures_rmac(img_path, model, RMAC=True, L = 3):\n",
        "\timg = prep_feat(img_path)\n",
        "\tfeatures = model.predict(img)\n",
        "\tresult = calculateMAC(features)\n",
        "\tif (RMAC):\n",
        "\t\tresult = calculateRMAC(features, L)\n",
        "\treturn result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy931O0ih92W"
      },
      "source": [
        "def get_feature_map_rmac():\n",
        "  features = []\n",
        "  img_names = []\n",
        "  for i, img_path in tqdm(enumerate(gallery)):\n",
        "    feature = extractFeatures_rmac(img_path,model)\n",
        "    img_name = os.path.split(img_path)[1]\n",
        "    feature /= np.linalg.norm(feature)\n",
        "    features.append(feature)\n",
        "    img_names.append(img_name)\n",
        "  features = np.array(features)\n",
        "  features = np.squeeze(features)\n",
        "  return features, img_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRE1ifZdz10z"
      },
      "source": [
        "def get_feature_map_fc():\n",
        "  features = []\n",
        "  img_names = []\n",
        "  for i, img_path in tqdm(enumerate(gallery)):\n",
        "    feature = extractFeatures_fc(img_path,model)\n",
        "    img_name = os.path.split(img_path)[1]\n",
        "    feature /= np.linalg.norm(feature)\n",
        "    features.append(feature)\n",
        "    img_names.append(img_name)\n",
        "  features = np.array(features)\n",
        "  features = np.squeeze(features)\n",
        "  return features, img_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MXV-0FsNvxc",
        "outputId": "de740435-42f6-48e0-f613-c2f5ef0e63f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rmac_features, rmac_img_names = get_feature_map_rmac()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49804it [50:34, 16.41it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSzL_9NiNetv"
      },
      "source": [
        "h5f = h5py.File('/content/drive/Shared drives/my_new_pan/4096-bn-rmac', 'w')\n",
        "h5f.create_dataset('dataset_1', data=rmac_features)\n",
        "h5f.create_dataset('dataset_2', data=np.string_(rmac_img_names))\n",
        "h5f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iZ0dFMjQyaq",
        "outputId": "5892ba75-3b6c-4e0c-d403-ab0d66bfbf44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fc_features, fc_img_names = get_feature_map_fc()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49804it [24:00, 34.57it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fabzUH1kmYlP"
      },
      "source": [
        "h5f = h5py.File('/content/drive/Shared drives/my_new_pan/4096-bn-rmac', 'w')\n",
        "h5f.create_dataset('dataset_1', data=fc_features)\n",
        "h5f.create_dataset('dataset_2', data=np.string_(fc_img_names))\n",
        "h5f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtxCOBcOZ04p"
      },
      "source": [
        "query = get_imlist('test_data_A/query')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzpuK4dNZ8A-",
        "outputId": "5b82f284-93ef-4715-f64f-61b9517b9640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(query)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9600"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHX11Vixl4Tp"
      },
      "source": [
        "def get_query_feature_map_rmac():\n",
        "  #first step inception\n",
        "  features = []\n",
        "  img_names = []\n",
        "  for i, img_path in tqdm(enumerate(query)):\n",
        "    feature = extractFeatures_rmac(img_path,model)\n",
        "    feature = np.squeeze(feature)\n",
        "    img_name = os.path.split(img_path)[1]\n",
        "    feature /= np.linalg.norm(feature)\n",
        "    features.append(feature)\n",
        "    img_names.append(img_name)\n",
        "  features = np.array(features)\n",
        "  features = np.squeeze(features)\n",
        "  return features, img_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4wM31Bkl5Uc",
        "outputId": "8515a8f3-b50f-4de6-bf3b-6144390548d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "query_features, query_img_names = get_query_feature_map_rmac()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9600it [10:07, 15.80it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbvtUohCl5Fr"
      },
      "source": [
        "h5f = h5py.File('/content/drive/Shared drives/my_new_pan/4096-bn-rmac_query', 'w')\n",
        "h5f.create_dataset('dataset_1', data=query_features\n",
        "h5f.create_dataset('dataset_2', data=np.string_(query_img_names)))\n",
        "h5f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAQwAiQrzyZR"
      },
      "source": [
        "**特征文件在以上已经存储完毕，在下方完成加载，开始计算**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhEAwyVaZswv"
      },
      "source": [
        "**欧式距离**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CU1-i_6gZ7-"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z6GveUIgLhW"
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXSw4DY_WanA"
      },
      "source": [
        "h5f = h5py.File('/content/drive/Shared drives/my_new_pan/4096-bn-rmac', 'r')\n",
        "feature = h5f['dataset_1'][:]\n",
        "imgNames = h5f['dataset_2'][:]\n",
        "h5f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwoMLSrymwDS"
      },
      "source": [
        "h5f = h5py.File('/content/drive/Shared drives/my_new_pan/4096-bn-rmac_query', 'r')\n",
        "queryfeature = h5f['dataset_1'][:]\n",
        "queryimgNames = h5f['dataset_2'][:]\n",
        "h5f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgyYew9b2tIB"
      },
      "source": [
        "retype_imgNames = [i.decode('utf-8') for i in imgNames]\n",
        "retype_queryimgNames = [i.decode('utf-8') for i in queryimgNames]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0vFN_ph3bd-",
        "outputId": "b10700a0-65d1-4f12-fa97-e9902f1450d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "submission = []\n",
        "for i in tqdm(range(len(queryimgNames))):\n",
        "  query_img_name = retype_queryimgNames[i]\n",
        "  query_feature = queryfeature[i]\n",
        "  score = []\n",
        "  for feat in feature:\n",
        "    score.append(np.linalg.norm(query_feature-feat))\n",
        "  rank_ID = np.argsort(score)\n",
        "  imlist = []\n",
        "\n",
        "  for index in rank_ID[0:10]:\n",
        "    imlist.append(retype_imgNames[index])\n",
        "\n",
        "  submission.append([query_img_name,str(imlist).replace('\\\"','').replace('\\'','').replace(' ','').replace('[','{').replace(']','}')])\n",
        " \n",
        "submission = np.array(submission)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9600/9600 [3:14:07<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlCfgygiKvvG"
      },
      "source": [
        "pd.DataFrame(submission).to_csv(\"/content/drive/Shared drives/my_new_pan/submission.csv\", header=None, index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk-bSWZrZnH8"
      },
      "source": [
        "**余弦相似度**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar8TZVweTb6W",
        "outputId": "dda0cce2-d1d9-44db-92b1-5d61a8a62dcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "submission = []\n",
        "for i in tqdm(range(len(queryimgNames))):\n",
        "  query_img_name = retype_queryimgNames[i]\n",
        "  query_feature = queryfeature[i]\n",
        "  score = []\n",
        "  for feat in feature:\n",
        "    cos = np.dot(feat,query_feature.T)/np.linalg.norm(feat)/np.linalg.norm(query_feature)\n",
        "    sin = 0.5 + 0.5 * cos\n",
        "    score.append(sin)\n",
        "  rank_ID = np.argsort(score)[::-1]\n",
        "  imlist = []\n",
        "  for index in rank_ID[0:10]:\n",
        "    imlist.append(retype_imgNames[index])\n",
        "  submission.append([query_img_name,str(imlist).replace('\\\"','').replace('\\'','').replace(' ','').replace('[','{').replace(']','}')])\n",
        "\n",
        "submission = np.array(submission)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9600/9600 [2:40:34<00:00,  1.00s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AguuoV-eTb2w"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2QmjDGZTbz4"
      },
      "source": [
        "pd.DataFrame(submission).to_csv(\"/content/drive/Shared drives/my_new_pan/submission.csv\", header=None, index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzdQlmemL5Zt"
      },
      "source": [
        "格式修整"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FxUM6nlMiYm"
      },
      "source": [
        "with open(\"/content/drive/Shared drives/my_new_pan/submission.csv\") as f:\n",
        "  contents = f.readlines()\n",
        "\n",
        "newcontents=[]\n",
        "for i in contents:\n",
        "  i = i.replace('\\\"','')\n",
        "  i = i.replace(' ','')\n",
        "  newcontents.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB7vttd0_-RD"
      },
      "source": [
        "with open(\"/content/drive/Shared drives/my_new_pan/submission2.csv\",'w') as f:\n",
        "  f.writelines(newcontents)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}